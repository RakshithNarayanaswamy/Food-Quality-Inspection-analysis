{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd7c4141-b6c2-4866-b228-7e05dca55d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import dlt\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    " \n",
    "@dlt.view\n",
    "def business_da_src():\n",
    "    return (\n",
    "        spark.readStream.table(\"workspace.food_inspection_project.silver_food_inspection_dallas\")\n",
    "        .where(col(\"restaurant_name\").isNotNull())\n",
    "        .selectExpr(\n",
    "            \"restaurant_name as business_key\",     \n",
    "            \"restaurant_name\",\n",
    "            \"street_address\",\n",
    "            \"current_timestamp() AS event_ts\"\n",
    "        )\n",
    "    )\n",
    " \n",
    "\n",
    "dlt.create_streaming_table(\"business_da_type2_stage\")\n",
    " \n",
    "dlt.apply_changes(\n",
    "    target=\"business_da_type2_stage\",\n",
    "    source=\"business_da_src\",\n",
    "    keys=[\"business_key\"],\n",
    "    sequence_by=\"event_ts\",\n",
    "    stored_as_scd_type=2,\n",
    "    ignore_null_updates=True\n",
    ")\n",
    " \n",
    "@dlt.table(name=\"dim_business_da_scd2\")\n",
    "def dim_business_da_scd2():\n",
    "    df = dlt.read(\"business_da_type2_stage\")\n",
    " \n",
    "    return (\n",
    "        df\n",
    "        .withColumnRenamed(\"__START_AT\",   \"effective_start_dt\")\n",
    "        .withColumnRenamed(\"__END_AT\",     \"effective_end_dt\")\n",
    "        .withColumnRenamed(\"__IS_CURRENT\", \"is_current\")\n",
    "        .withColumnRenamed(\"id\", \"business_key\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "439dc96c-d069-4953-b4f9-7432ee9d1eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(name=\"dim_business_da_scd2_v2\")\n",
    "def dim_business_da_scd2():\n",
    "    from pyspark.sql.window import Window\n",
    "    from pyspark.sql.functions import row_number\n",
    " \n",
    "    df = dlt.read(\"business_da_type2_stage\")\n",
    " \n",
    "    w = Window.orderBy(\"business_key\", \"__START_AT\")\n",
    " \n",
    "    df2 = (\n",
    "        df\n",
    "        .withColumn(\"row_num\", row_number().over(w))\n",
    "        .withColumnRenamed(\"__START_AT\", \"effective_start_dt\")\n",
    "        .withColumnRenamed(\"__END_AT\", \"effective_end_dt\")\n",
    "        .withColumnRenamed(\"__IS_CURRENT\", \"is_current\")\n",
    "    )\n",
    " \n",
    "    return df2"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Dallas_SCD2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}